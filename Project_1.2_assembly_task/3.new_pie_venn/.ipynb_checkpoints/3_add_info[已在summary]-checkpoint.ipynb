{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e847f4c5",
   "metadata": {},
   "source": [
    "# 1.for_all_pos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b319edc",
   "metadata": {},
   "source": [
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/compViridian_2/3_combination/2_pg_merge_all_pos_errorChecking_error.txt 'python3 /nfs/research/goldman/zihao/compViridian_2/3_combination/2_pg_merge_all_pos.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e407665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing /nfs/research/goldman/zihao/Datas/p1/Part1_2_for_assemble_data/2_combination/ERR6593117.txt: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m df_cov_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Decompress/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_coverage.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_cov_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df_cov \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(df_cov_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 获取所有 txt 文件\n",
    "files = glob.glob('/nfs/research/goldman/zihao/Datas/p1/Part1_2_for_assemble_data/2_combination/*.txt')\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        # 获取文件的 base name，例如 'ERR6367632.txt'\n",
    "        basename = os.path.basename(file)\n",
    "        # 去掉 .txt 后缀，获得 id，例如 'ERR6367632'\n",
    "        id = basename[:-4]\n",
    "\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "        df_cov_path = f\"/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Decompress/{id}_coverage.txt\"\n",
    "        if not os.path.exists(df_cov_path):\n",
    "            continue\n",
    "        df_cov = pd.read_csv(df_cov_path, sep='\\t')\n",
    "\n",
    "        df_ann_path = f\"/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Decompress/{id}_annot.txt\"\n",
    "        if not os.path.exists(df_ann_path):\n",
    "            continue\n",
    "        df_ann = pd.read_csv(df_ann_path, sep='\\t')\n",
    "\n",
    "        df_merge = pd.concat([df, df_cov['RATIO'], df_ann['AF'], df_ann['SB']], axis=1)\n",
    "\n",
    "        df_merge.to_csv(f\"/nfs/research/goldman/zihao/Datas/p1/Part1_2_for_assemble_data/merged_files_june/{id}.txt\", index=False, sep='\\t')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50986f71",
   "metadata": {},
   "source": [
    "#### 2.for_err_pos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f675e6",
   "metadata": {},
   "source": [
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/errorsProject_1/Part1_2_for_assemble/Part2_Compare/3_for_err_pos_errorChecking_error.txt 'python3 /nfs/research/goldman/zihao/errorsProject_1/Part1_2_for_assemble/Part2_Compare/3_for_err_pos.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_file(file_path, delimiter='\\t'):\n",
    "    \"\"\"Reads a file into a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(file_path, delimiter=delimiter)\n",
    "\n",
    "def fetch_file_path(folder_path, file_id, extension='.txt'):\n",
    "    \"\"\"Builds the file path from the folder path and file id.\"\"\"\n",
    "    return os.path.join(folder_path, f'{file_id}{extension}')\n",
    "\n",
    "def match_row(df, column, value):\n",
    "    \"\"\"Finds rows in a DataFrame that match a specific value in a specific column.\"\"\"\n",
    "    return df[df[column] == value]\n",
    "\n",
    "def append_columns(df_source, df_target, index, columns):\n",
    "    \"\"\"Appends columns from a source DataFrame to a target DataFrame.\"\"\"\n",
    "    df_target.loc[index, columns] = df_source[columns].values.tolist()[0]\n",
    "\n",
    "def save_file(df, file_path, columns, delimiter='\\t', index=False):\n",
    "    \"\"\"Saves a DataFrame to a file.\"\"\"\n",
    "    df[columns].to_csv(file_path, sep=delimiter, index=index)\n",
    "\n",
    "# Specify paths and column names \n",
    "a_file_path = '/nfs/research/goldman/zihao/errorsProject_1/MAPLE/new_version_MAY/output_modified.txt'\n",
    "b_folder_path = \"TEST/\"\n",
    "b_column_names = ['position', 'nucleotide_martin', 'nucleotide_origin', 'label', 'label2', 'label_mar', 'label_ori']\n",
    "output_file_path = 'output_data.txt'\n",
    "\n",
    "# Load the data from the 'A' file\n",
    "a_data = read_file(a_file_path)\n",
    "\n",
    "# Iterate through each row of the 'A' data\n",
    "for index, row in a_data.iterrows():\n",
    "    # Fetch the path of the corresponding 'B' file\n",
    "    b_file_path = fetch_file_path(b_folder_path, row['ID'])\n",
    "    \n",
    "    # Continue to the next iteration if the 'B' file doesn't exist\n",
    "    if not os.path.isfile(b_file_path):\n",
    "        continue\n",
    "\n",
    "    # Load the data from the 'B' file\n",
    "    b_data = read_file(b_file_path)\n",
    "\n",
    "    # Find the matching row in the 'B' data\n",
    "    matched_row = match_row(b_data, 'position', row['Position'])\n",
    "\n",
    "    # Continue to the next iteration if no matching row was found\n",
    "    if matched_row.empty:\n",
    "        print(f'No matching row found in {b_file_path} for ID {row[\"ID\"]} and position {row[\"Position\"]}.')\n",
    "        continue\n",
    "\n",
    "    # Append the necessary columns to the 'A' data\n",
    "    append_columns(matched_row, a_data, index, b_column_names)\n",
    "\n",
    "# Save the modified 'A' data\n",
    "save_file(a_data, output_file_path, ['ID', 'Position'] + b_column_names)\n",
    "\n",
    "print(f\"Data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfaf397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>nucleotide_martin</th>\n",
       "      <th>nucleotide_origin</th>\n",
       "      <th>label_masked</th>\n",
       "      <th>label_mar</th>\n",
       "      <th>label_ori</th>\n",
       "      <th>label_same</th>\n",
       "      <th>RATIO</th>\n",
       "      <th>AF</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>29899</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29899</th>\n",
       "      <td>29900</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>29901</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29901</th>\n",
       "      <td>29902</td>\n",
       "      <td>-</td>\n",
       "      <td>n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>29903</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29903 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       position nucleotide_martin nucleotide_origin  label_masked  label_mar  \\\n",
       "0             1                 -                 n             1          1   \n",
       "1             2                 -                 n             1          1   \n",
       "2             3                 -                 n             1          1   \n",
       "3             4                 -                 n             1          1   \n",
       "4             5                 -                 n             1          1   \n",
       "...         ...               ...               ...           ...        ...   \n",
       "29898     29899                 -                 n             1          1   \n",
       "29899     29900                 -                 n             1          1   \n",
       "29900     29901                 -                 n             1          1   \n",
       "29901     29902                 -                 n             1          1   \n",
       "29902     29903                 -                 -             1          1   \n",
       "\n",
       "       label_ori  label_same  RATIO   AF  SB  \n",
       "0              1           2    0.0  0.0   0  \n",
       "1              1           2    0.0  0.0   0  \n",
       "2              1           2    0.0  0.0   0  \n",
       "3              1           2    0.0  0.0   0  \n",
       "4              1           2    0.0  0.0   0  \n",
       "...          ...         ...    ...  ...  ..  \n",
       "29898          1           2    0.0  0.0   0  \n",
       "29899          1           2    0.0  0.0   0  \n",
       "29900          1           2    0.0  0.0   0  \n",
       "29901          1           2    0.0  0.0   0  \n",
       "29902          1           2    0.0  0.0   0  \n",
       "\n",
       "[29903 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3518b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5853e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84424c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1edb782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
