{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fe22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c56ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF</th>\n",
       "      <th>SB</th>\n",
       "      <th>REF_FWD</th>\n",
       "      <th>REF_REV</th>\n",
       "      <th>ALT_FWD</th>\n",
       "      <th>ALT_REV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>29899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29899</th>\n",
       "      <td>29900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>29901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29901</th>\n",
       "      <td>29902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>29903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29903 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POS REF ALT AF SB  REF_FWD  REF_REV  ALT_FWD  ALT_REV\n",
       "0          1   0   0  0  0        0        0        0        0\n",
       "1          2   0   0  0  0        0        0        0        0\n",
       "2          3   0   0  0  0        0        0        0        0\n",
       "3          4   0   0  0  0        0        0        0        0\n",
       "4          5   0   0  0  0        0        0        0        0\n",
       "...      ...  ..  .. .. ..      ...      ...      ...      ...\n",
       "29898  29899   0   0  0  0        0        0        0        0\n",
       "29899  29900   0   0  0  0        0        0        0        0\n",
       "29900  29901   0   0  0  0        0        0        0        0\n",
       "29901  29902   0   0  0  0        0        0        0        0\n",
       "29902  29903   0   0  0  0        0        0        0        0\n",
       "\n",
       "[29903 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function: split each key-value pair in INFO into two columns\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    keys = []\n",
    "    values = []\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            keys.append(key)\n",
    "            values.append(value)\n",
    "        else:\n",
    "            keys.append(field)\n",
    "            values.append(True)\n",
    "    return pd.Series(values, index=keys)\n",
    "\n",
    "# Read vcf files\n",
    "df = pd.read_csv('/nfs/research/goldman/zihao/Datas/p1/File_5_annot/SRR20358470.annot.vcf', delimiter='\\t', comment='#', header=None,\n",
    "                 dtype={0: str, 1: int, 2: str, 3: str, 4: str, 5: float, 6: str, 7: str})\n",
    "\n",
    "# Set column names\n",
    "df.columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "\n",
    "# Split the INFO column into multiple key-value pairs\n",
    "df_info = df['INFO'].apply(parse_info_field)\n",
    "\n",
    "# Add the processed result to the original data frame\n",
    "df = pd.concat([df, df_info], axis=1)\n",
    "\n",
    "# Split the string in column DP4 into 4 numbers\n",
    "df[['REF_FWD', 'REF_REV', 'ALT_FWD', 'ALT_REV']] = df['DP4'].str.split(',', expand=True).astype(int)\n",
    "\n",
    "# 删除'INDEL'列中为True的行\n",
    "df = df.drop(df[df['INDEL'] == True].index)\n",
    "df = df[['POS', 'REF', 'ALT', 'AF', 'SB', 'REF_FWD', 'REF_REV', 'ALT_FWD', 'ALT_REV']]\n",
    "# 创建一个新的索引\n",
    "new_index = pd.RangeIndex(start=1, stop=29904, step=1)\n",
    "\n",
    "# 重新索引数据框\n",
    "df = df.set_index('POS').reindex(new_index, fill_value=0).reset_index(drop=False).rename(columns={'index': 'POS'})\n",
    "\n",
    "# 将REF列、ALT列、AF列、SB列、REF_FWD列、REF_REV列、ALT_FWD列和ALT_REV列中的NaN值填充为0\n",
    "df[['REF', 'ALT', 'AF', 'SB', 'REF_FWD', 'REF_REV', 'ALT_FWD', 'ALT_REV']] = df[['REF', 'ALT', 'AF', 'SB', 'REF_FWD', 'REF_REV', 'ALT_FWD', 'ALT_REV']].fillna(0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "540281fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF</th>\n",
       "      <th>SB</th>\n",
       "      <th>REF_FWD</th>\n",
       "      <th>REF_REV</th>\n",
       "      <th>ALT_FWD</th>\n",
       "      <th>ALT_REV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>241</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1514</td>\n",
       "      <td>2457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     POS REF ALT        AF SB  REF_FWD  REF_REV  ALT_FWD  ALT_REV\n",
       "240  241   C   T  0.997989  0        1        1     1514     2457"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['POS']==241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "117c4fe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AF', 'SB'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mREF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mALT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 创建一个新的索引\u001b[39;00m\n\u001b[1;32m     50\u001b[0m new_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mRangeIndex(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m29904\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['AF', 'SB'] not in index\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/'\n",
    "output_dir = 'TEST_for_annot/'\n",
    "\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.annot.vcf.gz'))\n",
    "\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    parsed_info = {}\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            parsed_info[key] = value\n",
    "        else:\n",
    "            parsed_info[field] = True\n",
    "    return parsed_info\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    if i >= 10:\n",
    "        break\n",
    "\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.annot.vcf.gz', '_annot.txt'))\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            # Read vcf files\n",
    "            df = pd.read_csv(f, delimiter='\\t', comment='#', header=None,\n",
    "                             dtype={0: str, 1: int, 2: str, 3: str, 4: str, 5: float, 6: str, 7: str})\n",
    "\n",
    "            # Set column names\n",
    "            df.columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "\n",
    "            # Split the INFO column into multiple key-value pairs\n",
    "            df_info = df['INFO'].apply(parse_info_field)\n",
    "\n",
    "            # Add the processed result to the original data frame\n",
    "            df = pd.concat([df, df_info], axis=1)\n",
    "\n",
    "            # 删除'INDEL'列中为True的行\n",
    "            df = df.drop(df[df['INDEL'] == True].index)\n",
    "            df = df[['POS', 'REF', 'ALT', 'AF', 'SB', 'REF_FWD', 'REF_REV', 'ALT_FWD', 'ALT_REV']]\n",
    "            # 创建一个新的索引\n",
    "            new_index = pd.RangeIndex(start=1, stop=29904, step=1)\n",
    "\n",
    "            # 重新索引数据框\n",
    "            df = df.set_index('POS').reindex(new_index, fill_value=0).reset_index(drop=False).rename(columns={'index': 'POS'})\n",
    "\n",
    "            # 将REF列、ALT列、AF列、SB列、REF_FWD列、REF_REV列、ALT_FWD列和ALT_REV列中的NaN值填充为0\n",
    "            df[['REF', 'ALT', 'AF', 'SB']] = df[['REF', 'ALT', 'AF', 'SB']].fillna(0)\n",
    "\n",
    "            \n",
    "            with open(output_file, 'w', newline='') as outfile:\n",
    "                writer = csv.writer(outfile, delimiter='\\t')\n",
    "                writer.writerow(['POS', 'DP_RATIO', 'AF_RATIO', 'SB_RATIO'])\n",
    "                \n",
    "                for i, row in enumerate(rows):\n",
    "                    writer.writerow([row[0], dp_ratios[i], af_ratios[i], sb_ratios[i]])\n",
    "\n",
    "    except gzip.BadGzipFile:\n",
    "        print(f\"Skipping {file_path}: gzip decompression failed.\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "    except EOFError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba993e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005360e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SRR2030151: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1994967: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034282: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2091023: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2182246: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087318: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1994637: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104599: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2179370: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2090843: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087285: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087029: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR4637320: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087254: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104631: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1994943: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2103253: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034329: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2175953: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104596: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2088220: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1968615: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034212: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR7560007: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1991473: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2085712: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104505: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2091036: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087226: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1968622: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2088102: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2234403: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2169186: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2103633: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2030139: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2213195: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2145643: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR6423567: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1995010: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087207: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021464: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2163205: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR4891295: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1995045: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104629: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1020517: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021469: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR7849765: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021465: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087343: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1969991: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034481: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021335: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034276: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2223920: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034331: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021463: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1020517: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2088087: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1995008: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1969903: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2161333: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1991468: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2171816: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1970562: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR4438449: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034255: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2090879: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1984478: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2194789: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2211596: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2161325: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2171819: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2090967: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021343: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR1021087: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2087291: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104583: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2186726: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1968720: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034283: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2091059: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2103542: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2175960: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1969944: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2030140: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2179267: Compressed file ended before the end-of-stream marker was reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SRR2030135: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2034258: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1994871: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2091070: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2091040: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR1970564: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing SRR2104469: Compressed file ended before the end-of-stream marker was reached\n",
      "Error processing ERR6125368: Compressed file ended before the end-of-stream marker was reached\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/'\n",
    "output_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Decompress/'\n",
    "\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.annot.vcf.gz'))\n",
    "\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    parsed_info = {}\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            parsed_info[key] = value\n",
    "        else:\n",
    "            parsed_info[field] = True\n",
    "    return parsed_info\n",
    "\n",
    "def calculate_ratios(data, column_name):\n",
    "    total = sum(data)\n",
    "    mean = total / len(data) if len(data) > 0 else 0\n",
    "    ratios = [value / mean if mean != 0 else 0 for value in data]\n",
    "    return total, mean, ratios\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.annot.vcf.gz', '_annot.txt'))\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            \n",
    "            rows = []\n",
    "            dp_data, af_data, sb_data = [], [], []\n",
    "            \n",
    "            for row in reader:\n",
    "                if row[0].startswith('#'):\n",
    "                    continue\n",
    "                \n",
    "                info = parse_info_field(row[7])\n",
    "                dp = info.get('DP', '')\n",
    "                if dp:\n",
    "                    dp = float(dp)\n",
    "                else:\n",
    "                    dp = 0.0\n",
    "                af = info.get('AF', '')\n",
    "                if af:\n",
    "                    af = float(af)\n",
    "                else:\n",
    "                    af = 0.0\n",
    "                        \n",
    "                sb = info.get('SB', '')\n",
    "                if sb:\n",
    "                    sb = float(sb)\n",
    "                else:\n",
    "                    sb = 0.0\n",
    "\n",
    "                \n",
    "                dp_data.append(dp)\n",
    "                af_data.append(af)\n",
    "                sb_data.append(sb)\n",
    "                \n",
    "                rows.append([row[1], dp, af, sb])\n",
    "            \n",
    "            dp_sum, dp_mean, dp_ratios = calculate_ratios(dp_data, 'DP')\n",
    "            af_sum, af_mean, af_ratios = calculate_ratios(af_data, 'AF')\n",
    "            sb_sum, sb_mean, sb_ratios = calculate_ratios(sb_data, 'SB')\n",
    "            \n",
    "            with open(output_file, 'w', newline='') as outfile:\n",
    "                writer = csv.writer(outfile, delimiter='\\t')\n",
    "                writer.writerow(['POS', 'DP_RATIO', 'AF_RATIO', 'SB_RATIO'])\n",
    "                \n",
    "                for i, row in enumerate(rows):\n",
    "                    writer.writerow([row[0], dp_ratios[i], af_ratios[i], sb_ratios[i]])\n",
    "\n",
    "    except gzip.BadGzipFile:\n",
    "        print(f\"Skipping {file_path}: gzip decompression failed.\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "    except EOFError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7fc1d",
   "metadata": {},
   "source": [
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_deompress_errorChecking_error.txt  \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Annot/0_Apr.21_Decompress_and_save.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b7306",
   "metadata": {},
   "source": [
    "## For test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56c54b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/'\n",
    "output_dir = '/homes/zihao/DATAS/TEST_for_annot'\n",
    "\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.annot.vcf.gz'))\n",
    "\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    parsed_info = {}\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            parsed_info[key] = value\n",
    "        else:\n",
    "            parsed_info[field] = True\n",
    "    return parsed_info\n",
    "\n",
    "def calculate_ratios(data, column_name):\n",
    "    total = sum(data)\n",
    "    mean = total / len(data) if len(data) > 0 else 0\n",
    "    ratios = [value / mean if mean != 0 else 0 for value in data]\n",
    "    return total, mean, ratios\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    if i >= 1000:\n",
    "        break\n",
    "\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.annot.vcf.gz', '_annot.txt'))\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            reader = csv.reader(f, delimiter='\\t')\n",
    "            \n",
    "            rows = []\n",
    "            dp_data, af_data, sb_data = [], [], []\n",
    "            \n",
    "            for row in reader:\n",
    "                if row[0].startswith('#'):\n",
    "                    continue\n",
    "                \n",
    "                info = parse_info_field(row[7])\n",
    "                dp = float(info.get('DP', 0))\n",
    "                af = float(info.get('AF', 0))\n",
    "                sb = float(info.get('SB', 0))\n",
    "                \n",
    "                dp_data.append(dp)\n",
    "                af_data.append(af)\n",
    "                sb_data.append(sb)\n",
    "                \n",
    "                rows.append([row[1], dp, af, sb])\n",
    "            \n",
    "            dp_sum, dp_mean, dp_ratios = calculate_ratios(dp_data, 'DP')\n",
    "            af_sum, af_mean, af_ratios = calculate_ratios(af_data, 'AF')\n",
    "            sb_sum, sb_mean, sb_ratios = calculate_ratios(sb_data, 'SB')\n",
    "            \n",
    "            with open(output_file, 'w', newline='') as outfile:\n",
    "                writer = csv.writer(outfile, delimiter='\\t')\n",
    "                writer.writerow(['POS', 'DP_RATIO', 'AF_RATIO', 'SB_RATIO'])\n",
    "                \n",
    "                for i, row in enumerate(rows):\n",
    "                    writer.writerow([row[0], dp_ratios[i], af_ratios[i], sb_ratios[i]])\n",
    "\n",
    "    except gzip.BadGzipFile:\n",
    "        print(f\"Skipping {file_path}: gzip decompression failed.\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "    except EOFError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
