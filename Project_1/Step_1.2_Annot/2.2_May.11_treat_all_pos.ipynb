{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a49158",
   "metadata": {},
   "source": [
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/errorsProject_1/Annot/Treat_all_pos_errorChecking_error.txt \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_Treat_all_pos.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02f0aa",
   "metadata": {},
   "source": [
    "## Final Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "\n",
    "def check_files_with_id(folder_path, checkid_file, output_folder):\n",
    "    \"\"\"\n",
    "    Check the files in the given folder whose filenames contain the IDs in the specified files to the output folder.\n",
    "    \"\"\"\n",
    "    id_set = set()\n",
    "\n",
    "    with open(checkid_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                id_set.add(line[1:])\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(id_str in filename for id_str in id_set):\n",
    "            shutil.copy(os.path.join(folder_path, filename), os.path.join(output_folder, filename))\n",
    "            \n",
    "\n",
    "def process_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Integrate and merge all data (in preparation for later sampling)\n",
    "    \"\"\"\n",
    "    file_names = os.listdir(input_folder)\n",
    "\n",
    "    # Create a new txt file to store the file content\n",
    "    with open(os.path.join(output_folder, \"Annot_RATIO.txt\"), \"wt\") as output_file:\n",
    "        # Create a csv writer object and set the delimiter as '\\t'\n",
    "        writer = csv.writer(output_file, delimiter='\\t')\n",
    "        # Write the column names to the output file\n",
    "        writer.writerow([\"ID\", \"Position\", \"AF_Ratio\", \"SB_Ratio\"])\n",
    "\n",
    "        # Loop through the first N files with the extension '.txt' in the input folder\n",
    "        for i, file_name in enumerate(file_names):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                # Extract the file ID from the file name\n",
    "                file_id = file_name.split(\"_\")[0]\n",
    "                # Open the file, skip the header, and read the Position and Ratio columns\n",
    "                with open(os.path.join(input_folder, file_name), \"r\") as f:\n",
    "                    file_lines = f.readlines()[1:]\n",
    "                    # Loop through each line and write the ID, Position, and Ratio to the output file\n",
    "                    for line in file_lines:\n",
    "                        columns = line.strip().split(\"\\t\")\n",
    "                        position = columns[0]\n",
    "                        af = columns[3]\n",
    "                        sb = columns[4]\n",
    "                        writer.writerow([file_id, position, af, sb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0332af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Decompress/'\n",
    "checkid_file = \"/nfs/research/goldman/zihao/errorsProject_1/MAPLE/TEST_50000/MAPLE0.3.2_rateVar_errors_realData_checkingErrors_50000_estimatedErrors.txt\"\n",
    "middle_output_folder = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/PLOT_FOR_Annot/'\n",
    "\n",
    "output_folder = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Run the function\n",
    "check_files_with_id(folder_path, checkid_file, middle_output_folder)\n",
    "process_files(middle_output_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df35fa",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## For venn\n",
    "\n",
    "```bash\n",
    "bsub -M 20000 -e /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_sampling_all_errorChecking_error.txt 'python3 /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_sampling_all_pos.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36d92f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_files(data_file, input_file, output_file):\n",
    "    \"\"\"\n",
    "    This function reads two input files and writes specific rows from the second file\n",
    "    into the output file based on matching ID and Position from the first file.\n",
    "    \"\"\"\n",
    "    # Initialize the set to store ID and Position\n",
    "    id_position_set = set()\n",
    "\n",
    "    # Read the data file and store ID and Position\n",
    "    df = pd.read_csv(data_file, sep='\\t')\n",
    "    for _, row in df.iterrows():\n",
    "        id_position_str = '\\t'.join(map(str, [row['ID'], row['Position']]))\n",
    "        id_position_set.add(id_position_str)\n",
    "\n",
    "    # Read the input file and write matching data to the output file\n",
    "    with open(input_file, 'r') as input_file, open(output_file, 'w') as output_file:\n",
    "        next(input_file)  # Skip the title line\n",
    "        # Write the title line to the output file\n",
    "        output_file.write('ID\\tPosition\\tAF\\tSB\\n')\n",
    "        for line in input_file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            id_position_str = '\\t'.join(fields[:2])\n",
    "            if id_position_str in id_position_set:\n",
    "                output_file.write(line)\n",
    "                \n",
    "# Define the paths of your files\n",
    "data_file = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/selected_data.txt'\n",
    "input_file = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Annot_RATIO.txt'\n",
    "output_file = 'test.txt'  # Replace with the actual path of the output file\n",
    "\n",
    "# Call the function\n",
    "merge_files(data_file, input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911357ed",
   "metadata": {},
   "source": [
    "## Sampling (Not necessary)\n",
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/errorsProject_1/Annot/RS_errorChecking_error.txt 'python3 /nfs/research/goldman/zihao/errorsProject_1/Annot/RS_For_Annot.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64c1094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "\n",
    "def experiment_with_data(data_file, output_file):\n",
    "    selected_data = collections.defaultdict(list) \n",
    "    ## <defaultdict object> to ensure that \n",
    "    ## the memory occupied by the old value will be reclaimed by the garbage collection mechanism.\n",
    "\n",
    "    with open(data_file, 'r') as file:\n",
    "        next(file)\n",
    "        \n",
    "        # ！！！！！！！！！！！\n",
    "        line_count = 0  # 记录读取的行数\n",
    "        # ！！！！！！！！！！！\n",
    "        \n",
    "        for line in file:\n",
    "            \n",
    "            # ！！！！！！！！！！！\n",
    "            line_count += 1\n",
    "            if line_count > 299030:\n",
    "                break  # 停止读取数据\n",
    "            # ！！！！！！！！！！！\n",
    "\n",
    "            id_, position, af_ratio, sb_ratio = line.strip().split('\\t')\n",
    "            position = int(position)\n",
    "            af_ratio = float(af_ratio)\n",
    "            sb_ratio = float(sb_ratio)\n",
    "\n",
    "            if len(selected_data[position]) < 5:\n",
    "                selected_data[position].append((id_, af_ratio, sb_ratio))\n",
    "            else:\n",
    "                # Replace existing elements with a certain probability\n",
    "                s = int(random.uniform(0, len(selected_data[position])))\n",
    "                if s < 5:\n",
    "                    selected_data[position][s] = (id_, af_ratio, sb_ratio)\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"ID\\tPosition\\tAF_Ratio\\tSB_Ratio\\n\")\n",
    "        for position in selected_data:\n",
    "            for id_, af_ratio, sb_ratio in selected_data[position]:\n",
    "                file.write(f\"{id_}\\t{position}\\t{af_ratio}\\t{sb_ratio}\\n\")\n",
    "\n",
    "    print(\"选择的数据已保存到文件：\", output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf0420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择的数据已保存到文件： selected_data_1.txt\n"
     ]
    }
   ],
   "source": [
    "# 使用方法\n",
    "data_file = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Annot_RATIO.txt'\n",
    "output_file = 'selected_data_1.txt'\n",
    "experiment_with_data(data_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
