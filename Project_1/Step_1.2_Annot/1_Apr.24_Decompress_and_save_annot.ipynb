{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c367e2",
   "metadata": {},
   "source": [
    "## sample (middle part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad2a7c",
   "metadata": {},
   "source": [
    "ERR6684689.annot.vcf.gz   ERR7853477.annot.vcf.gz  SRR20975325.annot.vcf.gz  SRR23816670.annot.vcf.gz\n",
    "ERR6684690.annot.vcf.gz   ERR7853480.annot.vcf.gz  SRR20975327.annot.vcf.gz  SRR23816671.annot.vcf.gz\n",
    "ERR6684691.annot.vcf.gz   ERR7853482.annot.vcf.gz  SRR20975335.annot.vcf.gz  SRR23816672.annot.vcf.gz\n",
    "ERR6684695.annot.vcf.gz   ERR7853484.annot.vcf.gz  SRR20975342.annot.vcf.gz  SRR23816673.annot.vcf.gz\n",
    "ERR6684697.annot.vcf.gz   ERR7853485.annot.vcf.gz  SRR20975352.annot.vcf.gz  SRR23816674.annot.vcf.gz\n",
    "ERR6684700.annot.vcf.gz   ERR7853489.annot.vcf.gz  SRR20975354.annot.vcf.gz  SRR23816675.annot.vcf.gz\n",
    "ERR6684701.annot.vcf.gz   ERR7853491.annot.vcf.gz  SRR20975360.annot.vcf.gz  SRR23816677.annot.vcf.gz\n",
    "ERR6684702.annot.vcf.gz   ERR7853492.annot.vcf.gz  SRR20975371.annot.vcf.gz  SRR23816679.annot.vcf.gz\n",
    "ERR6684703.annot.vcf.gz   ERR7853493.annot.vcf.gz  SRR20975373.annot.vcf.gz  SRR23816680.annot.vcf.gz\n",
    "ERR6684704.annot.vcf.gz   ERR7853497.annot.vcf.gz  SRR20975384.annot.vcf.gz  SRR23816681.annot.vcf.gz\n",
    "ERR6684709.annot.vcf.gz   ERR7853500.annot.vcf.gz  SRR20975385.annot.vcf.gz  SRR23816682.annot.vcf.gz\n",
    "ERR6684710.annot.vcf.gz   ERR7853502.annot.vcf.gz  SRR20975391.annot.vcf.gz  SRR23816683.annot.vcf.gz\n",
    "ERR6684711.annot.vcf.gz   ERR7853504.annot.vcf.gz  SRR20975400.annot.vcf.gz  SRR23816684.annot.vcf.gz\n",
    "ERR6684712.annot.vcf.gz   ERR7853512.annot.vcf.gz  SRR20975405.annot.vcf.gz  SRR23816685.annot.vcf.gz\n",
    "ERR6684713.annot.vcf.gz   ERR7853514.annot.vcf.gz  SRR20975407.annot.vcf.gz  SRR23816686.annot.vcf.gz\n",
    "ERR6684714.annot.vcf.gz   ERR7853515.annot.vcf.gz  SRR20975408.annot.vcf.gz  SRR23816688.annot.vcf.gz\n",
    "ERR6684715.annot.vcf.gz   ERR7853516.annot.vcf.gz  SRR20975431.annot.vcf.gz  SRR23816690.annot.vcf.gz\n",
    "ERR6684717.annot.vcf.gz   ERR7853517.annot.vcf.gz  SRR20975447.annot.vcf.gz  SRR23816691.annot.vcf.gz\n",
    "ERR6684718.annot.vcf.gz   ERR7853519.annot.vcf.gz  SRR20975457.annot.vcf.gz  SRR23816692.annot.vcf.gz\n",
    "ERR6684720.annot.vcf.gz   ERR7853527.annot.vcf.gz  SRR20975458.annot.vcf.gz  SRR23816693.annot.vcf.gz\n",
    "ERR6684723.annot.vcf.gz   ERR7853528.annot.vcf.gz  SRR20975470.annot.vcf.gz  SRR23816694.annot.vcf.gz\n",
    "ERR6684724.annot.vcf.gz   ERR7853532.annot.vcf.gz  SRR20975477.annot.vcf.gz  SRR23816695.annot.vcf.gz\n",
    "ERR6684726.annot.vcf.gz   ERR7853535.annot.vcf.gz  SRR20975481.annot.vcf.gz  SRR23816696.annot.vcf.gz\n",
    "ERR6684728.annot.vcf.gz   ERR7853542.annot.vcf.gz  SRR20975482.annot.vcf.gz  SRR23816697.annot.vcf.gz\n",
    "ERR6684732.annot.vcf.gz   ERR7853543.annot.vcf.gz  SRR20975486.annot.vcf.gz  SRR23816698.annot.vcf.gz\n",
    "ERR6684735.annot.vcf.gz   ERR7853546.annot.vcf.gz  SRR20975491.annot.vcf.gz  SRR23816700.annot.vcf.gz\n",
    "ERR6684736.annot.vcf.gz   ERR7853550.annot.vcf.gz  SRR20975493.annot.vcf.gz  SRR23816701.annot.vcf.gz\n",
    "ERR6684737.annot.vcf.gz   ERR7853551.annot.vcf.gz  SRR20975497.annot.vcf.gz  SRR23816702.annot.vcf.gz\n",
    "ERR6684739.annot.vcf.gz   ERR7853554.annot.vcf.gz  SRR20975499.annot.vcf.gz  SRR23816703.annot.vcf.gz\n",
    "ERR6684741.annot.vcf.gz   ERR7853556.annot.vcf.gz  SRR20975519.annot.vcf.gz  SRR23816704.annot.vcf.gz\n",
    "ERR6684742.annot.vcf.gz   ERR7853559.annot.vcf.gz  SRR20975520.annot.vcf.gz  SRR23816705.annot.vcf.gz\n",
    "ERR6684743.annot.vcf.gz   ERR7853560.annot.vcf.gz  SRR20975521.annot.vcf.gz  SRR23816706.annot.vcf.gz\n",
    "ERR6684744.annot.vcf.gz   ERR7853561.annot.vcf.gz  SRR20975524.annot.vcf.gz  SRR23816707.annot.vcf.gz\n",
    "ERR6684745.annot.vcf.gz   ERR7853562.annot.vcf.gz  SRR20975528.annot.vcf.gz  SRR23816708.annot.vcf.gz\n",
    "ERR6684748.annot.vcf.gz   ERR7853565.annot.vcf.gz  SRR20975533.annot.vcf.gz  SRR23816711.annot.vcf.gz\n",
    "ERR6684751.annot.vcf.gz   ERR7853566.annot.vcf.gz  SRR20975535.annot.vcf.gz  SRR23816712.annot.vcf.gz\n",
    "ERR6684753.annot.vcf.gz   ERR7853568.annot.vcf.gz  SRR20975544.annot.vcf.gz  SRR23816713.annot.vcf.gz\n",
    "ERR6684754.annot.vcf.gz   ERR7853569.annot.vcf.gz  SRR20975545.annot.vcf.gz  SRR23816714.annot.vcf.gz\n",
    "ERR6684756.annot.vcf.gz   ERR7853572.annot.vcf.gz  SRR20975550.annot.vcf.gz  SRR23816715.annot.vcf.gz\n",
    "ERR6684759.annot.vcf.gz   ERR7853576.annot.vcf.gz  SRR20975551.annot.vcf.gz  SRR23816716.annot.vcf.gz\n",
    "ERR6684761.annot.vcf.gz   ERR7853577.annot.vcf.gz  SRR20975552.annot.vcf.gz  SRR23816717.annot.vcf.gz\n",
    "ERR6684763.annot.vcf.gz   ERR7853581.annot.vcf.gz  SRR20975553.annot.vcf.gz  SRR23816718.annot.vcf.gz\n",
    "ERR6684765.annot.vcf.gz   ERR7853582.annot.vcf.gz  SRR20975557.annot.vcf.gz  SRR23816719.annot.vcf.gz\n",
    "ERR6684768.annot.vcf.gz   ERR7853585.annot.vcf.gz  SRR20975558.annot.vcf.gz  SRR23816720.annot.vcf.gz\n",
    "ERR6684769.annot.vcf.gz   ERR7853587.annot.vcf.gz  SRR20975560.annot.vcf.gz  SRR23816721.annot.vcf.gz\n",
    "ERR6684770.annot.vcf.gz   ERR7853590.annot.vcf.gz  SRR20975561.annot.vcf.gz  SRR23816722.annot.vcf.gz\n",
    "ERR6684772.annot.vcf.gz   ERR7853592.annot.vcf.gz  SRR20975565.annot.vcf.gz  SRR23816723.annot.vcf.gz\n",
    "ERR6684773.annot.vcf.gz   ERR7853595.annot.vcf.gz  SRR20975566.annot.vcf.gz  SRR23816724.annot.vcf.gz\n",
    "ERR6684774.annot.vcf.gz   ERR7853598.annot.vcf.gz  SRR20975568.annot.vcf.gz  SRR23816725.annot.vcf.gz\n",
    "ERR6684775.annot.vcf.gz   ERR7853600.annot.vcf.gz  SRR20975581.annot.vcf.gz  SRR23816726.annot.vcf.gz\n",
    "ERR6684778.annot.vcf.gz   ERR7853601.annot.vcf.gz  SRR20975588.annot.vcf.gz  SRR23816727.annot.vcf.gz\n",
    "ERR6684779.annot.vcf.gz   ERR7853602.annot.vcf.gz  SRR20975589.annot.vcf.gz  SRR23816728.annot.vcf.gz\n",
    "ERR6684780.annot.vcf.gz   ERR7853603.annot.vcf.gz  SRR20975592.annot.vcf.gz  SRR23816729.annot.vcf.gz\n",
    "ERR6684781.annot.vcf.gz   ERR7853604.annot.vcf.gz  SRR20975594.annot.vcf.gz  SRR23816730.annot.vcf.gz\n",
    "ERR6684782.annot.vcf.gz   ERR7853608.annot.vcf.gz  SRR20975595.annot.vcf.gz  SRR23816731.annot.vcf.gz\n",
    "ERR6684783.annot.vcf.gz   ERR7853610.annot.vcf.gz  SRR20975613.annot.vcf.gz  SRR23816732.annot.vcf.gz\n",
    "ERR6684784.annot.vcf.gz   ERR7853613.annot.vcf.gz  SRR20975618.annot.vcf.gz  SRR23816733.annot.vcf.gz\n",
    "ERR6684786.annot.vcf.gz   ERR7853614.annot.vcf.gz  SRR20975621.annot.vcf.gz  SRR23816734.annot.vcf.gz\n",
    "ERR6684787.annot.vcf.gz   ERR7853615.annot.vcf.gz  SRR20975627.annot.vcf.gz  SRR23816735.annot.vcf.gz\n",
    "ERR6684788.annot.vcf.gz   ERR7853616.annot.vcf.gz  SRR20975631.annot.vcf.gz  SRR23816736.annot.vcf.gz\n",
    "ERR6684790.annot.vcf.gz   ERR7853617.annot.vcf.gz  SRR20975632.annot.vcf.gz  SRR23816737.annot.vcf.gz\n",
    "ERR6684791.annot.vcf.gz   ERR7853620.annot.vcf.gz  SRR20975634.annot.vcf.gz  SRR23816738.annot.vcf.gz\n",
    "ERR6684792.annot.vcf.gz   ERR7853621.annot.vcf.gz  SRR20975636.annot.vcf.gz  SRR23816739.annot.vcf.gz\n",
    "ERR6684794.annot.vcf.gz   ERR7853622.annot.vcf.gz  SRR20975641.annot.vcf.gz\n",
    "ERR6684798.annot.vcf.gz   ERR7853623.annot.vcf.gz  SRR20975647.annot.vcf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcd9d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>29899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29899</th>\n",
       "      <td>29900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>29901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29901</th>\n",
       "      <td>29902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>29903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29903 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POS REF ALT   AF SB\n",
       "0          1   0   0  0.0  0\n",
       "1          2   0   0  0.0  0\n",
       "2          3   0   0  0.0  0\n",
       "3          4   0   0  0.0  0\n",
       "4          5   0   0  0.0  0\n",
       "...      ...  ..  ..  ... ..\n",
       "29898  29899   0   0  0.0  0\n",
       "29899  29900   0   0  0.0  0\n",
       "29900  29901   0   0  0.0  0\n",
       "29901  29902   0   0  0.0  0\n",
       "29902  29903   0   0  0.0  0\n",
       "\n",
       "[29903 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define function: split each key-value pair in INFO into two columns\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    keys = []\n",
    "    values = []\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            keys.append(key)\n",
    "            values.append(value)\n",
    "        else:\n",
    "            keys.append(field)\n",
    "            values.append(True)\n",
    "    return pd.Series(values, index=keys)\n",
    "\n",
    "# Read vcf file\n",
    "df = pd.read_csv('/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/SRR20975647.annot.vcf.gz', delimiter='\\t',comment='#', header=None,\n",
    "                 dtype={0: str, 1: int, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str})\n",
    "\n",
    "# Set column names\n",
    "df.columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "\n",
    "# Split the INFO column into multiple key-value pairs\n",
    "df_info = df['INFO'].apply(parse_info_field)\n",
    "\n",
    "# Add the processed result to the original data frame\n",
    "df = pd.concat([df, df_info], axis=1)\n",
    "\n",
    "# Drop rows based on the value of the 'INDEL' column, if it is present\n",
    "if 'INDEL' in df.columns:\n",
    "    df = df.drop(df[df['INDEL'] == True].index)\n",
    "\n",
    "# Create AF and SB columns and set them to 0 if they don't exist\n",
    "if 'AF' not in df.columns:\n",
    "    df['AF'] = 0\n",
    "if 'SB' not in df.columns:\n",
    "    df['SB'] = 0\n",
    "\n",
    "# Transform AF > 0.5\n",
    "df['AF'] = df['AF'].astype(float)\n",
    "df.loc[df['AF'] > 0.5, 'AF'] = 1 - df['AF']\n",
    "\n",
    "\n",
    "# Extract desired columns\n",
    "df = df[['POS', 'REF', 'ALT', 'AF', 'SB']]\n",
    "\n",
    "# 创建一个新的索引\n",
    "new_index = pd.RangeIndex(start=1, stop=29904, step=1)\n",
    "\n",
    "# 重新索引数据框\n",
    "df = df.set_index('POS').reindex(new_index, fill_value=0).reset_index(drop=False).rename(columns={'index': 'POS'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b090e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AF</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29898</th>\n",
       "      <td>29899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29899</th>\n",
       "      <td>29900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29900</th>\n",
       "      <td>29901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29901</th>\n",
       "      <td>29902</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29902</th>\n",
       "      <td>29903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29903 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         POS REF ALT   AF  SB\n",
       "0          1   0   0  0.0   0\n",
       "1          2   0   0  0.0   0\n",
       "2          3   0   0  0.0   0\n",
       "3          4   0   0  0.0   0\n",
       "4          5   0   0  0.0   0\n",
       "...      ...  ..  ..  ...  ..\n",
       "29898  29899   0   0  0.0   0\n",
       "29899  29900   0   0  0.0   0\n",
       "29900  29901   0   0  0.0   0\n",
       "29901  29902   0   0  0.0   0\n",
       "29902  29903   0   0  0.0   0\n",
       "\n",
       "[29903 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define function: split each key-value pair in INFO into two columns\n",
    "def parse_info_field(info_str):\n",
    "    fields = info_str.split(';')\n",
    "    keys = []\n",
    "    values = []\n",
    "    for field in fields:\n",
    "        if '=' in field:\n",
    "            key, value = field.split('=')\n",
    "            keys.append(key)\n",
    "            values.append(value)\n",
    "        else:\n",
    "            keys.append(field)\n",
    "            values.append(True)\n",
    "    return pd.Series(values, index=keys)\n",
    "\n",
    "# Read vcf file\n",
    "df = pd.read_csv('/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/SRR23816718.annot.vcf.gz', delimiter='\\t',comment='#', header=None,\n",
    "                 dtype={0: str, 1: np.int64, 2: str, 3: str, 4: str, 5: str, 6: str, 7: str}, compression='gzip')\n",
    "\n",
    "# Set column names\n",
    "df.columns = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "\n",
    "# Split the INFO column into multiple key-value pairs\n",
    "df_info = df['INFO'].apply(parse_info_field)\n",
    "\n",
    "# Add the processed result to the original data frame\n",
    "df = pd.concat([df, df_info], axis=1)\n",
    "\n",
    "# Drop rows based on the value of the 'INDEL' column, if it is present\n",
    "if 'INDEL' in df.columns:\n",
    "    df = df.drop(df[df['INDEL'] == True].index)\n",
    "\n",
    "# Create AF and SB columns and set them to 0 if they don't exist\n",
    "if 'AF' not in df.columns:\n",
    "    df['AF'] = 0\n",
    "if 'SB' not in df.columns:\n",
    "    df['SB'] = 0\n",
    "\n",
    "# Transform AF > 0.5\n",
    "df['AF'] = df['AF'].astype(float)\n",
    "df.loc[df['AF'] > 0.5, 'AF'] = 1 - df['AF']\n",
    "\n",
    "#### >>>>>>>>>>>>>>>>>> 以下是新功能 <<<<<<<<<<<<<<<<<\n",
    "# Ensure 'REF' and 'ALT' are of type string\n",
    "df['REF'] = df['REF'].astype(str)\n",
    "df['ALT'] = df['ALT'].astype(str)\n",
    "\n",
    "# Filter rows where 'REF' and 'ALT' have only one letter\n",
    "df = df[(df['REF'].str.len() <= 1) & (df['ALT'].str.len() <= 1)]\n",
    "#### >>>>>>>>>>>>>>>>>> 以上是新功能 <<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Extract desired columns\n",
    "df = df[['POS', 'REF', 'ALT', 'AF', 'SB']]\n",
    "\n",
    "# Drop duplicates in 'POS' column\n",
    "df = df.drop_duplicates(subset='POS', keep='first')\n",
    "\n",
    "# Create a new index\n",
    "new_index = pd.RangeIndex(start=1, stop=29904, step=1)\n",
    "\n",
    "# Re-index the data frame\n",
    "df = df.set_index('POS').reindex(new_index, fill_value=0).reset_index(drop=False).rename(columns={'index': 'POS'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b7306",
   "metadata": {},
   "source": [
    "## For test / also for final version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7fc1d",
   "metadata": {},
   "source": [
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_decompress_errorChecking_error.txt \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Annot/Annot_Decompress_and_save.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58265190",
   "metadata": {},
   "source": [
    "##### csv版本_test_封装class后，未封装版在Annot_Decompress_and_save.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82ef0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "class VCFProcessor:\n",
    "    def __init__(self, input_dir, output_dir):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_info_field(info_str):\n",
    "        \"\"\"Parse the INFO field of a VCF file and return a dictionary.\"\"\"\n",
    "        info_dict = {}\n",
    "        for field in info_str.split(';'):\n",
    "            if '=' in field:\n",
    "                key, value = field.split('=')\n",
    "                info_dict[key] = value\n",
    "        return info_dict\n",
    "\n",
    "    def process_vcf_file(self, file_path):\n",
    "        \"\"\"Process a single VCF file and return the processed data.\"\"\"\n",
    "        try:\n",
    "            data = {}\n",
    "            new_data = []\n",
    "\n",
    "            with gzip.open(file_path, 'rt') as file:\n",
    "                reader = csv.reader(file, delimiter='\\t')\n",
    "\n",
    "                for row in reader:\n",
    "                    if not row or row[0].startswith('#'):\n",
    "                        continue\n",
    "\n",
    "                    chrom, pos, id_, ref, alt, qual, filter_, info = row\n",
    "                    pos = int(pos)\n",
    "                    info_dict = self.parse_info_field(info)\n",
    "\n",
    "                    if 'INDEL' in info_dict and info_dict['INDEL'] == True:\n",
    "                        continue\n",
    "                        \n",
    "                    # Skip the current loop if 'REF' or 'ALT' have more than one character\n",
    "                    if len(ref) > 1 or len(alt) > 1:\n",
    "                        continue\n",
    "\n",
    "                    ref = ref if ref else '0'\n",
    "                    alt = alt if alt else '0'\n",
    "                    af = info_dict.get('AF', '0')\n",
    "                    sb = info_dict.get('SB', '0')\n",
    "                    \n",
    "                    af = float(af)\n",
    "                    if af > 0.5:\n",
    "                        af = 1 - af\n",
    "\n",
    "                    if pos not in data:\n",
    "                        data[pos] = [pos, ref, alt, af, sb]\n",
    "\n",
    "            for idx in range(1, length_of_sample):\n",
    "                if idx in data:\n",
    "                    new_data.append(data[idx])\n",
    "                else:\n",
    "                    new_data.append([idx, 'NA', 'NA', '0', '0'])\n",
    "\n",
    "            return new_data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unknown error processing {file_path}: {e}\")\n",
    "\n",
    "    def process_files(self):\n",
    "        \"\"\"Process all VCF files in the input directory and write the results to the output directory.\"\"\"\n",
    "        \n",
    "        file_paths = glob.glob(os.path.join(self.input_dir, '*.annot.vcf.gz'))\n",
    "\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            \n",
    "            # Remove this line for the final version！！！！\n",
    "            if i >= 10:  \n",
    "                break\n",
    "            # Remove this line for the final version！！！！\n",
    "\n",
    "            output_file = os.path.join(self.output_dir, os.path.basename(file_path).replace('.annot.vcf.gz', '_annot.txt'))\n",
    "\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"{output_file} already exists. Skipping file {file_path}.\")\n",
    "                continue\n",
    "\n",
    "            result = self.process_vcf_file(file_path)\n",
    "            if result is None:\n",
    "                continue\n",
    "\n",
    "            with open(output_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f, delimiter='\\t')\n",
    "                writer.writerow(['POS', 'REF', 'ALT', 'AF', 'SB'])\n",
    "                writer.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75ab27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31521560",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    length_of_sample = 29904 # the true number +1 (eg: 29903 should be 29904)\n",
    "    input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/'\n",
    "    output_dir = '/homes/zihao/DATAS/TEST_for_annot_new_may/'\n",
    "    processor = VCFProcessor(input_dir, output_dir)\n",
    "    processor.process_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
