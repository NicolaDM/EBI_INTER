{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ca4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ed0c5",
   "metadata": {},
   "source": [
    "### 0. Decompress and save coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a335bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all vcf files in the input directory\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Downloads/'\n",
    "output_dir = '/homes/zihao/DATAS/TEST_for_annot/'\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.annot.vcf.gz'))\n",
    "\n",
    "# Process the first 10 vcf files\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    if i >= 10: #!!!!!!!!!!!正式版删除\n",
    "        break\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.annot.vcf.gz', '_annot.txt'))\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"{output_file} already exists. Skipping file {file_path}.\")\n",
    "        continue\n",
    "\n",
    "    # Process the vcf file\n",
    "    result = process_vcf_file(file_path)\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    # Write the results to a text file\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['POS', 'REF', 'ALT', 'AF', 'SB'])\n",
    "        writer.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f97c0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/zihao/TEST/SRR20920168_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/SRR20920168.coverage.gz.\n",
      "/homes/zihao/TEST/ERR4908531_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR4908531.coverage.gz.\n",
      "/homes/zihao/TEST/ERR7093094_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR7093094.coverage.gz.\n",
      "/homes/zihao/TEST/SRR22391894_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/SRR22391894.coverage.gz.\n",
      "/homes/zihao/TEST/SRR20507431_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/SRR20507431.coverage.gz.\n",
      "/homes/zihao/TEST/ERR6624907_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR6624907.coverage.gz.\n",
      "/homes/zihao/TEST/SRR21152334_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/SRR21152334.coverage.gz.\n",
      "/homes/zihao/TEST/ERR6580345_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR6580345.coverage.gz.\n",
      "/homes/zihao/TEST/ERR6498063_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR6498063.coverage.gz.\n",
      "/homes/zihao/TEST/ERR8009037_coverage.txt already exists. Skipping file /nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/ERR8009037.coverage.gz.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/'\n",
    "output_dir = '/homes/zihao/TEST/'\n",
    "\n",
    "# 获取所有以 .coverage.gz 结尾的文件路径\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.coverage.gz'))\n",
    "\n",
    "# 遍历每个文件，并将结果存储到一个列表中\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # 只处理前1000个文件\n",
    "    if i >= 10:\n",
    "        break\n",
    "    # 构造输出文件名\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.coverage.gz', '_coverage.txt'))\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"{output_file} already exists. Skipping file {file_path}.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            lines = [line.strip() for line in f if not line.startswith('##')]\n",
    "            data = [line.split('\\t') for line in lines[0:]]\n",
    "            new_data = []\n",
    "            for row in data:\n",
    "                position, n, coverage_str = row[0].split(',')\n",
    "                coverage = int(coverage_str)\n",
    "                new_data.append([position, n, coverage])\n",
    "            total_coverage = sum(row[2] for row in new_data)\n",
    "            mean_coverage = total_coverage / len(new_data)\n",
    "            ratio_data = [[row[0], row[1], row[2] / mean_coverage] for row in new_data]\n",
    "            # 将结果保存到文本文件中\n",
    "            with open(output_file, 'w') as out_f:\n",
    "                out_f.write('Position\\tN\\tRATIO\\n')\n",
    "                for row in ratio_data:\n",
    "                    out_f.write('\\t'.join(str(col) for col in row) + '\\n')\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Unknown error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2fb9256",
   "metadata": {},
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/'\n",
    "output_dir = '/homes/zihao/P1/'\n",
    "\n",
    "# 获取所有以 .coverage.gz 结尾的文件路径\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.coverage.gz'))\n",
    "\n",
    "# 遍历每个文件，并将结果存储到一个列表中\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # 只处理前1000个文件\n",
    "    if i >= 1000:\n",
    "        break\n",
    "    # 构造输出文件名\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.coverage.gz', '_coverage.txt'))\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            lines = [line for line in f if not line.startswith('##')]\n",
    "            data = [line.strip().split('\\t') for line in lines[0:]]\n",
    "            df = pd.DataFrame(data)\n",
    "            df[['Position', 'N', 'Coverage']] = df.iloc[:, 0].str.split(',', expand=True)\n",
    "            df = df.drop(df.columns[[0, 2]], axis=1)\n",
    "            df['SUM'] = df['Coverage'].astype(int).sum()\n",
    "            df['MEAN'] = df['SUM']/len(df)\n",
    "            df['RATIO'] = df['Coverage'].astype(int)/df['MEAN'].astype(int)\n",
    "            df = df.drop(['SUM','MEAN'], axis=1)\n",
    "            # 将结果保存到文本文件中\n",
    "            df.to_csv(output_file, sep='\\t', header=True, index=False)\n",
    "            # 删除DataFrame，释放内存\n",
    "            del df\n",
    "    except gzip.BadGzipFile:\n",
    "        print(f\"Skipping {file_path}: gzip decompression failed.\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "    except EOFError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e9dec",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "input_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Downloads/'\n",
    "output_dir = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Decompress/'\n",
    "\n",
    "# Get all file paths that end with .coverage.gz\n",
    "file_paths = glob.glob(os.path.join(input_dir, '*.coverage.gz'))\n",
    "\n",
    "# Traverse each file and store the results in a list\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    # Construct the output file name\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path).replace('.coverage.gz', '_coverage.txt'))\n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt') as f:\n",
    "            lines = [line for line in f if not line.startswith('##')]\n",
    "            data = [line.strip().split('\\t') for line in lines[0:]]\n",
    "            df = pd.DataFrame(data)\n",
    "            df[['Position', 'N', 'Coverage']] = df.iloc[:, 0].str.split(',', expand=True)\n",
    "            df = df.drop(df.columns[[0, 2]], axis=1)\n",
    "            df['SUM'] = df['Coverage'].astype(int).sum()\n",
    "            df['MEAN'] = df['SUM']/len(df)\n",
    "            df['RATIO'] = df['Coverage'].astype(int)/df['MEAN'].astype(int)\n",
    "            df = df.drop(['SUM','MEAN'], axis=1)\n",
    "            # Save the results to a text file\n",
    "            df.to_csv(output_file, sep='\\t', header=True, index=False)\n",
    "            # Delete the DataFrame to free up memory\n",
    "            del df\n",
    "    except gzip.BadGzipFile:\n",
    "        print(f\"Skipping {file_path}: gzip decompression failed.\")\n",
    "        continue\n",
    "    except IndexError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "    except EOFError as e:\n",
    "        file_id = os.path.basename(file_path)[:10]\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "        continue\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
