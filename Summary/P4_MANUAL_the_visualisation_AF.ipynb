{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a0abf7",
   "metadata": {},
   "source": [
    "# <center>A visualisation study of AF(allele frequency) on Viridian's assembly & Colman's assembly</center>\n",
    "##### <center>MANUAL</center>\n",
    "\n",
    "\n",
    "\n",
    "| **Label** | **start time** | **finish time** | **last modified** |\n",
    "|:--------------:|:-----------:|:-----------:|:----------------:|\n",
    "|   Project 4   |  2023-07-10 |  2023-07-26 |   2023-07-26     |\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "```python\n",
    "# CODE: \n",
    "/nfs/research/goldman/zihao/N_errorsProject_1_P4\n",
    "# DATA:\n",
    "/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4\n",
    "# Path/to/figure\n",
    "/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_visualisation\n",
    "```\n",
    "**Tips：** All the codes need to change the path has been marked in the code as below:\n",
    "  \n",
    "  \\# ==================Requires modification==================  \n",
    "  \\# Path to be changed  \n",
    "  \\# ==================Requires modification==================\n",
    "    \n",
    "  \n",
    "\\*path/to/A\\*:  means that this file needs to be changed for different needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16cce1",
   "metadata": {},
   "source": [
    "# <center>Catalog:</center>\n",
    "- 1. [Data preparation for AF](#1.Data_preparation)\n",
    "    - [1) Decompress and save AF](#1.1_Decompress_and_save_Annot)\n",
    "    - [2) Merging AF information with nucleotide information](#1.2_Processing_and_merging_of_data)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 2. [Extraction of locations for which MAPLE indicates an error and sampling of all locations](#2.Data_consolidation)\n",
    "    - [1) Decompress and save coverage](#2.1_processing_for_Error_positions)\n",
    "    - [2.2) Processing for all positions](#2.2_processing_for_All_positions)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 3. [Visualization](#3.Visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4954e7",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 1.Data_preparation\n",
    "[Return to Catalog](#Catalog:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018e357",
   "metadata": {},
   "source": [
    "***\n",
    "### 1.1_Decompress_and_save_Annot\n",
    "\n",
    "- **Idea**: \n",
    "In the old plot we were showing the frequency of the minor allele (always <50%). Now we do the same but instead of the minor allele to use the allele (nucleotide) in Colman’s assembly, which might be <50% or >50%. \n",
    "\n",
    "- **Input**: Downloaded files\n",
    "- **Output**:\n",
    "```python\n",
    "output_directories = ['/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Folder_Decompress_forP4/']\n",
    "```\n",
    "- **Address**:\n",
    "```python\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_decompress/annotDecompress_andSave.py\n",
    "```\n",
    "\n",
    "##### Code block:\n",
    "**!!!Tips: All samples have now been processed and do not need to be repeated!!!**\n",
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_decompress/Folder_Checking/errorChecking.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_decompress/Folder_Checking/outputChecking.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_decompress/annotDecompress_andSave.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5024769",
   "metadata": {},
   "source": [
    "### 1.2_Processing_and_merging_of_data\n",
    "- **Idea**:\n",
    "Merged with AF data using neuclotide at each position for each sample of Viridan's assembly and Colman's assembly extracted in P2 (/nfs/research/goldman/zihao/Datas/p2_comp_viridian/3_combination/*.txt)\n",
    "\n",
    "- **Input**: \n",
    "```python\n",
    "/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Folder_Decompress_forP4/*.txt\n",
    "/nfs/research/goldman/zihao/Datas/p2_comp_viridian/3_combination/*.txt\n",
    "```\n",
    "- **Output**:\n",
    "```python\n",
    "*missingID_dir* = '/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_treatedAF/Folder_missingID'\n",
    "missing_id_file_path = f\"{missingID_dir}/missing_file1_ids.txt\"\n",
    "missing_file2_id_file_path = f\"{missingID_dir}/missing_file2_ids.txt\"\n",
    "\n",
    "*output_dir* = '/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_treatedAF/folderData_treatedFile'\n",
    "```\n",
    "- **Address**:\n",
    "```python\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing/dataProcessing.py\n",
    "```\n",
    "\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing/Folder_Checking/errorChecking.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing/Folder_Checking/outputChecking.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing/dataProcessing.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e6e72",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 2.Data_consolidation\n",
    "[Return to Catalog](#Catalog:)\n",
    "\n",
    "##### Code block:\n",
    "```bash\n",
    "sh /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/bash_combColANDVir.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450464e",
   "metadata": {},
   "source": [
    "## !!!Or enter the commends step by step!!!\n",
    "### 2.1_processing_for_Error_positions\n",
    "- **Idea**:\n",
    "The locations of MAPLE labelled errors were extracted separately for Viridan's assembly and Colman's assembly , and AF and nucleotide information was extracted\n",
    "\n",
    "- **Input**: \n",
    "```python\n",
    "### get from P3 - 1.Data_Preparation\n",
    "# Viridian：\n",
    "/nfs/research/goldman/zihao/Datas/p2_compViridian_P3/Folder_mapleOutput/VIR_output_modified.txt\n",
    "# Colman:\n",
    "/nfs/research/goldman/zihao/Datas/p2_compViridian_P3/Folder_mapleOutput/COL_output_modified.txt\n",
    "\n",
    "/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_treatedAF/folderData_treatedFile/merged_{ID}.txt\n",
    "```\n",
    "- **Output**:\n",
    "```python\n",
    "output_dir = '/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_combFor_errPos/'\n",
    "# Viridian：\n",
    "missing_ids_file = os.path.join(output_dir, 'missing_idsVir.txt')\n",
    "output_csv_file = os.path.join(output_dir, 'errPos_combForvir.txt')\n",
    "# Colman:\n",
    "missing_ids_file = os.path.join(output_dir, 'missing_idsCol.txt')\n",
    "output_csv_file = os.path.join(output_dir, 'errPos_combForcol.txt')\n",
    "```\n",
    "- **Address**:\n",
    "```python\n",
    "# Viridian：\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_errPos_combVir.py\n",
    "# Colman:\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_errPos_combCol.py\n",
    "```\n",
    "\n",
    "##### Code block:\n",
    "\n",
    "###### Viridian：\n",
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/errPos_errorChecking_forVir.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/errPos_outputChecking_forVir.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_errPos_combVir.py'\n",
    "```\n",
    "###### Colman:\n",
    "```bash\n",
    "bsub -M 2000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/errPos_errorChecking_forCol.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/errPos_outputChecking_forCol.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_errPos_combCol.py'\n",
    "```\n",
    "### 2.2_processing_for_All_positions\n",
    "- **Idea**:\n",
    "Here I have used random sampling without putback. First calculate how many locations need to be sampled for each file and then start sampling, since not every location has AF information, there is no need to sample every location as before.\n",
    "\n",
    "- **Input**: \n",
    "```python\n",
    "/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_treatedAF/folderData_treatedFile/merged_{ID}.txt\n",
    "```\n",
    "- **Output**:\n",
    "```python\n",
    "output_dir = '/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_combFor_allPos/'\n",
    "# Viridian：\n",
    "output_file = \"allPos_combForvir.txt\"\n",
    "# Colman:\n",
    "output_file = \"allPos_combForcol.txt\"\n",
    "```\n",
    "- **Address**:\n",
    "```python\n",
    "# Viridian：\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_allPos_combVir.py\n",
    "# Colman:\n",
    "/nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_allPos_combCol.py\n",
    "```\n",
    "\n",
    "##### Code block:\n",
    "\n",
    "###### Viridian：\n",
    "```bash\n",
    "bsub -M 20000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/allPos_errorChecking_forVir.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/allPos_outputChecking_forVir.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_allPos_combVir.py'\n",
    "```\n",
    "###### Colman:\n",
    "```bash\n",
    "bsub -M 20000 -e /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/allPos_errorChecking_forCol.txt -o /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/Folder_Checking/allPos_outputChecking_forCol.txt 'python3 /nfs/research/goldman/zihao/Code/errorsProject_1_P4/Folder_processing_Comb/pg_allPos_combCol.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932391a",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 3.Visualization\n",
    "[Return to Catalog](#Catalog:)\n",
    "```python\n",
    "/nfs/research/goldman/zihao/Code/jupyterLab/Project_1_errorAnalysis/2.forAF_P4/3.1_densityPlot.ipynb\n",
    "```\n",
    "\n",
    "### **Output**:\n",
    "```python\n",
    "# output_dir： \n",
    "/nfs/research/goldman/zihao/Datas/p1_errorsProject_P4/Folder_visualisation\n",
    "```\n",
    "- 1.PLOT_sameAsREF.png: \n",
    "    - Viridian's assembly & Colman's assembly 's nucleotides Same as reference's\n",
    "- 2.PLOT_sameALT.png\n",
    "    - Viridian's assembly & Colman's assembly 's nucleotides Same as alternative's\n",
    "- 3.PLOT_diff.png\n",
    "    - Viridian's assembly & Colman's assembly 's nucleotides different from ref & alt's\n",
    "- 4.PLOT_masked.png\n",
    "    - Viridian's assembly & Colman's assembly 's nucleotides have been masked (All positions only)\n",
    "- 5.PLOT_masked_err&all.png\n",
    "    - Viridian's assembly & Colman's assembly 's nucleotides have been masked (+errPosVIR-Masked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
