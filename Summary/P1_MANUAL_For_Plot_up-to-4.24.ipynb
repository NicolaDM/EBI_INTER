{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a367c555",
   "metadata": {},
   "source": [
    "# Treat_error_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc1c09",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Decompress and save coverage [Done]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed70af2",
   "metadata": {},
   "source": [
    "- **Idea**: Decompress the coverage file and save it after processing (calculate the **RATIO**[NB_COVERAGE/MEAN_nb_coverage])\n",
    "```python\n",
    "    lines = [line for line in f if not line.startswith('##')]\n",
    "    data = [line.strip().split('\\t') for line in lines[0:]]\n",
    "    df = pd.DataFrame(data)\n",
    "    df[['Position', 'N', 'Coverage']] = df.iloc[:, 0].str.split(',', expand=True)\n",
    "    df = df.drop(df.columns[[0, 2]], axis=1)\n",
    "    df['SUM'] = df['Coverage'].astype(int).sum()\n",
    "    df['MEAN'] = df['SUM']/len(df)\n",
    "    df['RATIO'] = df['Coverage'].astype(int)/df['MEAN'].astype(int)\n",
    "    df = df.drop(['SUM','MEAN'], axis=1)\n",
    "```\n",
    "- **Input**:Downloaded files\n",
    "- **Output**:\n",
    "```python\n",
    "output_directories = ['/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Decompress/*_coverage.txt']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385da377",
   "metadata": {},
   "source": [
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000\n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Coverage/Decompress_errorChecking_error.txt 'python3 /nfs/research/goldman/zihao/errorsProject_1/Coverage/python3 0_Apr.21_Decompress_and_save.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab38fa",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Handle with output.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a1230",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"/nfs/research/goldman/zihao/errorsProject_1/MAPLE/MapleRealErrorsVariation_errorEstimation_estimatedErrors.txt\" ### !!!Needs to be modified!!!\n",
    "output_folder = \"/homes/zihao/P1/\" ### !!!Needs to be modified!!!\n",
    "\n",
    "# Open the output file to write the processed data\n",
    "with open(os.path.join(output_folder, \"output_modified.txt\"), \"w\") as output_file:\n",
    "    # Write the column headers to the output file\n",
    "    output_file.write(\"ID\\tPosition\\n\")\n",
    "    \n",
    "    # Initialize the current_id variable to None\n",
    "    current_id = None\n",
    "    \n",
    "    # Iterate over each line in the file and convert it to a list\n",
    "    with open(file_path, \"r\") as input_file:\n",
    "        for line in input_file:\n",
    "            if line.startswith(\">\"):\n",
    "                # Update current_id if a new ID is encountered\n",
    "                current_id = line[1:].strip()\n",
    "            else:\n",
    "                tokens = line.strip().split()\n",
    "                position = int(tokens[0])\n",
    "                base = tokens[1]\n",
    "                percentage = float(tokens[2])\n",
    "\n",
    "                # Check if percentage is less than 0.5, and if so, skip adding it to the processed data\n",
    "                if percentage < 0.5:\n",
    "                    continue\n",
    "\n",
    "                # Write the processed data to the output file\n",
    "                output_file.write(f\"{current_id}\\t{position}\\n\")\n",
    "                \n",
    "                # Delete variables to free up memory\n",
    "                del tokens, base, position, percentage\n",
    "                \n",
    "    # Delete the current_id variable after the loop has finished\n",
    "    del current_id\n",
    "\n",
    "print(f\"Processing complete and file written to {output_folder}.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d814b",
   "metadata": {},
   "source": [
    "- **Idea**: Collate the output format and remove those with an error rate less than 0.5\n",
    "- **Input**: MapleRealErrorsVariation_errorEstimation_estimatedErrors.txt\n",
    "- **Output**: output_modified.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29c5f9",
   "metadata": {},
   "source": [
    "***\n",
    "### 3. Data Processing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbc6f3",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def search_position_value_and_get_column_4(file_path, id_position):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        file_header = f.readline().strip().split(\"\\t\")\n",
    "        position_column_index = file_header.index(\"Position\")\n",
    "        column_4_index = 2\n",
    "\n",
    "        for line in f:\n",
    "            line_values = line.strip().split(\"\\t\")\n",
    "            if position_column_index < len(line_values): # Check if index is within range\n",
    "                position_value = int(line_values[position_column_index])\n",
    "                if position_value == id_position and column_4_index < len(line_values):\n",
    "                    return line_values[column_4_index]\n",
    "    return None\n",
    "\n",
    "\n",
    "def process_data(data_file_path, directory_to_search, output_file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(data_file_path, \"r\") as f:\n",
    "        header = f.readline().strip().split(\"\\t\")\n",
    "        header.append(\"MEAN_err\")\n",
    "\n",
    "        for line in f:\n",
    "            data.append(line.strip().split(\"\\t\") + [None])\n",
    "\n",
    "    for line in data:\n",
    "        id_now = str(line[0])\n",
    "        id_position = line[1]\n",
    "\n",
    "        if id_position is not None:\n",
    "            for filename in os.listdir(directory_to_search):\n",
    "                if id_now in filename and filename.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(directory_to_search, filename)\n",
    "                    result = search_position_value_and_get_column_4(file_path, int(id_position))\n",
    "                    if result is not None:\n",
    "                        line[-1] = result\n",
    "                        break\n",
    "\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        f.write(\"\\t\".join(header) + \"\\n\")\n",
    "        for line in data:\n",
    "            f.write(\"\\t\".join(str(x) for x in line) + \"\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbb69d",
   "metadata": {},
   "source": [
    "```python\n",
    "directory_to_search = \"/homes/zihao/P1/TEST_1/\" ### !!!Needs to be modified!!!\n",
    "data_file_path = \"output_modified.txt\" ### !!!Needs to be modified!!!\n",
    "output_file_path = \"processed_data.txt\" ### !!!Needs to be modified!!!\n",
    "\n",
    "process_data(data_file_path, directory_to_search, output_file_path)\n",
    "\n",
    "# Handling files without corresponding IDs\n",
    "df = pd.read_csv(output_file_path, sep='\\t')\n",
    "## Delete rows where RATIO is None\n",
    "df = df.replace(\"None\", np.nan)\n",
    "df = df.dropna(subset=[\"MEAN_err\"])\n",
    "\n",
    "## Calculate the mean from the position\n",
    "df[\"MEAN_err\"] = df[\"MEAN_err\"].astype(float)\n",
    "df_err = df.groupby(by=[\"Position\"], as_index=False).mean(numeric_only=True)\n",
    "df_err.to_csv(output_file_path, sep='\\t')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa25029",
   "metadata": {},
   "source": [
    "- **Idea**: Find the coverage ratio by ID as primary key and return to add it to the input file\n",
    "- **Input**: output_modified.txt\n",
    "- **Output**: processed_data.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5204c9e",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Treat_all_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deacf77e",
   "metadata": {},
   "source": [
    "#### Eliminate IDs that do not correspond to coverage data\n",
    "```python\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Load a list of IDs from a file\n",
    "df_err = pd.read_csv(\"processed_data.txt\", sep='\\t') ### !!!Needs to be modified!!!\n",
    "id_set = set(df_err['ID'])\n",
    "\n",
    "# Set the folder path\n",
    "folder_path = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Decompress/'\n",
    "\n",
    "# Create a new directory for the copied files\n",
    "if not os.path.exists(folder_path + '../AAA'):\n",
    "    os.makedirs(folder_path + '../AAA')\n",
    "\n",
    "# Copy files that match the IDs to the new directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the filename contains any ID in the set\n",
    "    if any(id_str in filename for id_str in id_set):\n",
    "        # Copy the file to the new directory\n",
    "        shutil.copy(os.path.join(folder_path, filename), os.path.join(folder_path, '../AAA', filename))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce94f75",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set folder path\n",
    "folder_path = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/AAA/'\n",
    "\n",
    "# Get all files in the folder\n",
    "files = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "# Read the first file\n",
    "df = pd.read_csv(files[0], sep='\\t')\n",
    "ratios = df['RATIO'].tolist()\n",
    "\n",
    "# Set the output file name\n",
    "output_file = '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/processed_data_all.txt'  ### !!!Needs to be modified!!!\n",
    "\n",
    "# Write the average value to a txt file\n",
    "with open(output_file, 'w') as f:\n",
    "    # Write the header\n",
    "    f.write('MEAN_pos\\n')\n",
    "\n",
    "    # Write the average value of the first file\n",
    "    f.write('\\n'.join(map(str, ratios)))\n",
    "    f.write('\\n')\n",
    "\n",
    "    # Delete the ratios variable from memory\n",
    "    del ratios\n",
    "\n",
    "    # Loop through the remaining files\n",
    "    for file in files[1:]:\n",
    "        try:\n",
    "            # Read the file using pandas\n",
    "            df_new = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "            # Calculate the average value of RATIO in each file\n",
    "            ratios_new = df_new['RATIO'].tolist()\n",
    "            ratios = np.mean([ratios, ratios_new], axis=0)\n",
    "\n",
    "            # Write the average value to the txt file (overwriting previous content)\n",
    "            with open(output_file, 'w') as f_out:\n",
    "                # Write the header\n",
    "                f_out.write('MEAN_pos\\n')\n",
    "\n",
    "                # Write the current average value\n",
    "                f_out.write('\\n'.join(map(str, ratios)))\n",
    "                f_out.write('\\n')\n",
    "\n",
    "            # Delete the ratios variable from memory\n",
    "            del ratios\n",
    "\n",
    "        except:\n",
    "            # If there is an error, skip the current file\n",
    "            pass\n",
    "```      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa31300",
   "metadata": {},
   "source": [
    "- **Idea**: \n",
    "- **Input**: \n",
    "- **Output**: processed_data_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b28ee",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d887ac",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "from plotly.offline import iplot, plot\n",
    "\n",
    "df_err = pd.read_csv(\"processed_data.txt\", sep='\\t')  ### !!!Needs to be modified!!!\n",
    "df_all = pd.read_csv('/homes/zihao/P1/processed_data_all.txt', sep='\\t')  ### !!!Needs to be modified!!!\n",
    " \n",
    "\n",
    "# Visualization\n",
    "hist_data = [df_err['MEAN_err'].tolist(), df_all['MEAN_pos'].tolist()]\n",
    "group_labels = ['error position', 'all position'] # name of the dataset\n",
    "colors = ['#7FA6EE', '#B8F7D4']\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels, curve_type='normal', colors=colors, bin_size=.5)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Blank for now\",\n",
    "    yaxis=dict(\n",
    "        title='Frequency',\n",
    "        showline=True, showgrid=False,\n",
    "        linewidth=2, linecolor='gray', ticks='outside',\n",
    "        tickfont=dict(\n",
    "            family='Arial',\n",
    "            size=12,\n",
    "            color='black',\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    xaxis=dict(\n",
    "        title='The ratio of coverage vs mean coverage',\n",
    "        showline=True, showgrid=False,\n",
    "        linewidth=2, linecolor='gray', ticks='outside',\n",
    "        tickfont=dict(\n",
    "            family='Arial',\n",
    "            size=12,\n",
    "            color='black',\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(size=12),\n",
    "    ),\n",
    "\n",
    "    plot_bgcolor='white',\n",
    "    yaxis_gridcolor='lightgray', yaxis_gridwidth=0.5,\n",
    "    xaxis_gridcolor='lightgray', xaxis_gridwidth=0.5,\n",
    ")\n",
    "# fig.show()\n",
    "plot(fig, filename='my_plot.html') ### !!!Needs to be modified!!!\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
