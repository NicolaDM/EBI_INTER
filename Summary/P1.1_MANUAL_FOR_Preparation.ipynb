{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2860d5",
   "metadata": {},
   "source": [
    "## <center>Document the preparation of the first project and the use of MAPLE </center>\n",
    "##### <center>MANUAL</center>\n",
    "\n",
    "\n",
    "\n",
    "| **Label** | **start time** | **finish time** | **last modified** |\n",
    "|:--------------:|:-----------:|:-----------:|:----------------:|\n",
    "|   Project 1   |  2023-04-11 |  2023-04-20 |   2023-04-27     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443c445",
   "metadata": {},
   "source": [
    "# 0. Possible preparations needed\n",
    "- Install anaconda [Check here](https://docs.anaconda.com/free/anaconda/install/) [Not necessary]\n",
    "    - Connect to jupyter\n",
    "\n",
    "##### Code block:\n",
    "```bash\n",
    "export PATH=\"/$HOME/anaconda3/bin:$PATH\"\n",
    "\n",
    "export PATH=\"$PATH:$HOME/anaconda/bin\"\n",
    "\n",
    "cd\n",
    "\n",
    "jupyter-notebook --no-browser --ip=0.0.0.0 --port=9999\n",
    "\n",
    "```\n",
    "\n",
    "- Install MAFFT [Check here](https://mafft.cbrc.jp/alignment/software/installation_without_root.html) [Important!!!]\n",
    "\n",
    "**User's Manual**:  Start from 3. [Data Processing](#3.Data_Processing)\n",
    "- Enter the steps in !!**Code block**!! below separately\n",
    "\n",
    "Tips: In order to find out the error in time, I strongly recommend following this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e843c4",
   "metadata": {},
   "source": [
    "# <center>Catalog:</center>\n",
    "- 1. [Data Analysis](#1.Data_Analysis)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 2. [Data Preparation](#2.Data_Preparation)\n",
    "    - [1) Picking_5_files](#2.1.Picking_5_files)\n",
    "    - [2) Splitting_files_by_type](#2.2.Splitting_files_by_type)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 3. [Data Processing](#3.Data_Processing)\n",
    "    - [1) Data slicing](#3.1.Data_slicing(for_easy_download))\n",
    "    - [2) Data Download](#3.2.Data_Download)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 4. [Adjust sequence format](#4.Adjust_sequence_format)\n",
    "    - [1) Decompress](#4.1.Decompress)\n",
    "        - [i) Sequence Alignment](#4.1.1_Sequence_Alignment)\n",
    "    \n",
    "    - [2) Delete Reference](#4.2.Delete_Reference)\n",
    "    - [3) Merge and Remove blank](#4.3.Merge_and_Remove_blank)\n",
    "    - [4) Transform as the MAPLE format](#4.4.Transform_as_the_MAPLE_format)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- 5. [Run MAPLE program](#5.Run_MAPLE_program)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030122b",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 1.Data_Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7639058",
   "metadata": {},
   "source": [
    "### For this project, we have two datasets:\n",
    "#### 1. analysis_run_list.txt\n",
    "- Location:\n",
    "```python \n",
    "/nfs/research/goldman/zihao/Datas/p1/Origin_Data/analysis_run_list.txt\n",
    "```\n",
    "- Function: show the number of files with the corresponding sample ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b8c8c",
   "metadata": {},
   "source": [
    "#### 2. analysis_full_06.04.23.txt\n",
    "- Location:\n",
    "```python \n",
    "/nfs/research/goldman/zihao/Datas/p1/Origin_Data/analysis_full_06.04.23.txt\n",
    "```\n",
    "- Function: Provide download addresses for different types of data for each sample\n",
    "\n",
    "- The example is shown below, but because this is a large dataset, only the first 100 are shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2addf0",
   "metadata": {},
   "source": [
    "For our task, we will need \n",
    "- coverage: Display the number of covered segments\n",
    "- annot: Display annotations of gene samples at different locations, such as raw depth, mutations, etc.\n",
    "- and consensus: Sequence of sample genes\n",
    "\n",
    "but this is only for samples with five files, so we need to split (i.e. filter out samples with five files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b16cb",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 2.Data_Preparation\n",
    "[Return to Catalog](#Catalog:)\n",
    "\n",
    "###### Code:\n",
    "Data_Preparation_5_files.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753086c",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.1.Picking_5_files\n",
    "The processing idea is as follows:\n",
    "- To read data from a data file row by row, you can use Pandas' read_csv() function and set the chunksize parameter to read the data chunk by chunk.\n",
    "- For each chunk of data, iterate through each row and process it.\n",
    "- For each row, compare the \"run_id\" in another file, if it exists, store the run_id and FTP_path of the row in a dictionary, and write the data in the dictionary to a text file.\n",
    "- If it does not exist, skip the row of data directly.\n",
    "- Delete the block of data and continue reading the next block of data.\n",
    "- [!!!] But at the same time we found that some files have more than one FTP link(Points to the same file), which will cause duplicate downloads and waste download resources, so we do the de-duplicate process\n",
    "\n",
    "###### Output's location:\n",
    "```python \n",
    "/nfs/research/goldman/zihao/Datas/p1/Origin_Data/file_5_script.txt # Before de-duplication\n",
    "/nfs/research/goldman/zihao/Datas/p1/Origin_Data/File_5.txt # After de-duplication\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f0bb2",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.2.Splitting_files_by_type\n",
    "###### Output's location:\n",
    "```python \n",
    "/nfs/research/goldman/zihao/Datas/p1/File_5_Coverage.txt # For Coverage\n",
    "/nfs/research/goldman/zihao/Datas/p1/File_5_Annot.txt # For Annot\n",
    "/nfs/research/goldman/zihao/Datas/p1/File_5_Consensus.txt # For Consensus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dcd19",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 3.Data_Processing\n",
    "[Return to Catalog](#Catalog:)\n",
    "\n",
    "***\n",
    "### 3.1.Data_slicing(for_easy_download))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599b741",
   "metadata": {},
   "source": [
    "- **Idea**: cut all files into 100 copies so that they can be downloaded at the same time\n",
    "- **Input**:\n",
    "```python\n",
    "input_files = ['/nfs/research/goldman/zihao/Datas/p1/File_5_Annot.txt',\n",
    "               '/nfs/research/goldman/zihao/Datas/p1/File_5_Consensus.txt',\n",
    "               '/nfs/research/goldman/zihao/Datas/p1/File_5_Coverage.txt']\n",
    "```\n",
    "- **Output**:\n",
    "```python\n",
    "output_directories = ['/nfs/research/goldman/zihao/Datas/p1/File_5_annot/Datas/batch*.txt',\n",
    "                      '/nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Datas/batch*.txt',\n",
    "                      '/nfs/research/goldman/zihao/Datas/p1/File_5_coverage/Datas/batch*.txt']\n",
    "```\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/1_Download/Data_slicing.py\n",
    "```\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/1_Download/Data_slicing_errorChecking_error.txt  \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/1_Download/Data_slicing.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659a16c",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.2.Data_Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64898b3",
   "metadata": {},
   "source": [
    "- **Idea**: Download the corresponding sample files from the files cut in the previous steps while following the FTP link\n",
    "\n",
    "\n",
    "- **Input&Output**:\n",
    "```python\n",
    "for use_case in \"File_5_annot\" \"File_5_consensus\" \"File_5_coverage\"; do\n",
    "      input_folder_path=\"$input_base_path/$use_case/Datas\"\n",
    "      output_folder_path=\"$output_base_path/$use_case/Downloads\"\n",
    "```\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/1_Download/run_data_download.sh\n",
    "/nfs/research/goldman/zihao/errorsProject_1/1_Download/D_file_5_script.py\n",
    "```\n",
    "##### Code block:\n",
    "```bash\n",
    "cd /nfs/research/goldman/zihao/errorsProject_1/1_Download\n",
    "\n",
    "sh run_data_download.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43b76a",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 4.Adjust_sequence_format\n",
    "[Return to Catalog](#Catalog:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0fa076",
   "metadata": {},
   "source": [
    "1. Put all the downloaded consensus sequences in a single fasta file (let’s call it all_consensuses.fasta ).\n",
    "    \n",
    "2. Run mafft with the special options we mentioned before including --keeplength and using the reference I sent you MN908947.3 , let’s call the output all_consensuses_aligned.fasta .\n",
    "    \n",
    "3. Remove the reference sequence from the mafft alignment output (it should be the first sequence in the file), let’s call the resulting file all_consensuses_aligned_noReference.fasta .\n",
    "    \n",
    "4. Run my script createMapleFile.py on  all_consensuses_aligned_noReference.fasta WITHOUT using option --reference . This will create a MAPLE file for you, and a new reference to use with MAPLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a6ba6",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.1.Decompress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176d20a",
   "metadata": {},
   "source": [
    "- **Idea**: Decompress the downloaded file\n",
    "- **Input**: All files downloaded in the previous step\n",
    "\n",
    "- **Output**: \n",
    "    - all_consensuses_batch_*.fasta\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/Consensuses/Decompress.py\n",
    "```\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Decompress_errorChecking_error.txt \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Decompress.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def89d6",
   "metadata": {},
   "source": [
    "### 4.1.1_Sequence_Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b90f2",
   "metadata": {},
   "source": [
    "- **Idea**: Alignment using MAFFT software and according to MN908947.3 as reference\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "for i in {1..20}\n",
    "do\n",
    "  mafft --6merpair --keeplength --addfragments \"/nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Decompress/all_consensuses_batch_$i.fasta\" \"/nfs/research/goldman/zihao/errorsProject_1/Consensuses/ref_MN908947.3.fasta\" > \"/nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Decompress/aligned_$i.fasta\"\n",
    "done\n",
    "```\n",
    "\n",
    "- **Input**: All files decompressed in the previous step\n",
    "\n",
    "- **Output**: \n",
    "    - /nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Decompress/aligned/aligned_*.fasta\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/Consensuses/Aligned.sh\n",
    "``` \n",
    "##### Code block:\n",
    "```bash\n",
    "cd /nfs/research/goldman/zihao/errorsProject_1/Consensuses\n",
    "sh Aligned.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7051963",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.2.Delete_Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1fdb1",
   "metadata": {},
   "source": [
    "- **Idea**: Delete reference MN908947.3\n",
    "\n",
    "- **Input**: All files aligned in the previous step\n",
    "\n",
    "- **Output**: \n",
    "    - all_consensuses_aligned_noReference_aligned_*.fasta\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/Consensuses/Del_ref.py\n",
    "```\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000\n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Del_ref_errorChecking_error.txt  \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Del_ref.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e452980",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.3.Merge_and_Remove_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f52f5d1",
   "metadata": {},
   "source": [
    "- Input: all_consensuses_aligned_noReference_aligned_*.fasta\n",
    "\n",
    "- Output: \n",
    "    - After merge: all_consensuses_aligned_noReference.fasta\n",
    "\n",
    "    - After Remove: rm_blank_all_consensuses_aligned_noReference.fasta\n",
    "- **Location**： \n",
    "```python\n",
    "/nfs/research/goldman/zihao/errorsProject_1/Consensuses/Merge_Remove_blank.py\n",
    "```\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub -M 2000 \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Merge_Remove_errorChecking_error.txt  \n",
    "'python3 /nfs/research/goldman/zihao/errorsProject_1/Consensuses/Merge_Remove_blank.py'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4061f",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.4.Transform_as_the_MAPLE_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b205bc6a",
   "metadata": {},
   "source": [
    "Run the script createMapleFile.py on  all_consensuses_aligned_noReference.fasta WITHOUT using option --reference . This will create a MAPLE file for you, and a new reference to use with MAPLE.\n",
    "\n",
    "##### Code block:\n",
    "```bash\n",
    "bsub \"/hps/software/users/goldman/pypy3/pypy3.7-v7.3.5-linux64/bin/pypy3 \n",
    "createMapleFile.py \n",
    "--path /nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Decompress/Aligned/noReference/ \n",
    "--fasta rm_blank_all_consensuses_aligned_noReference.fasta \n",
    "--output MAPLE_format_consensuses.txt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e21978b",
   "metadata": {},
   "source": [
    "### Explanation of MAPLE format\n",
    "#### > SRR20944325\n",
    "\n",
    "|         |         |         |\n",
    "|---------|---------|---------|\n",
    "| - | 1 | 2 |\n",
    "| n | 3 | 29901 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58922471",
   "metadata": {},
   "source": [
    "- The second column number tells you the genome position the entry refers to.\n",
    "\n",
    "- The third column\n",
    "    - If the third column is not present, then the entry refers to only one position.\n",
    "    - If the third column is present, its value tells you how many positions that entry refers to\n",
    "\n",
    "- For example\n",
    "|         |         |         |\n",
    "|---------|---------|---------|\n",
    "| n | 541 | 10 |\n",
    "\n",
    "    - means that “n” is present in the sequence in ten consecutive positions from position 541 up to position 550."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702081d1",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# 5.Run_MAPLE_program\n",
    "[Return to Catalog](#Catalog:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8414de4",
   "metadata": {},
   "source": [
    "##### Code block:\n",
    "```bash\n",
    "bsub -g /MapleRealErrors_3 -q long -M 40000 \n",
    "-o /nfs/research/goldman/zihao/errorsProject_1/MAPLE/new_version_MAY/MAPLE_realData_errorChecking_output_new_all.txt \n",
    "-e /nfs/research/goldman/zihao/errorsProject_1/MAPLE/new_version_MAY/MAPLE_realData_errorChecking_error_new_all.txt \n",
    "/hps/software/users/goldman/pypy3/pypy3.7-v7.3.5-linux64/bin/pypy3 /nfs/research/goldman/demaio/fastLK/code/MAPLEv0.3.2.py \n",
    "--model UNREST --rateVariation --estimateSiteSpecificErrorRate \n",
    "--input /nfs/research/goldman/zihao/Datas/p1/File_5_consensus/Decompress/Aligned/noReference/A_NEW_MAPLE_format/MAPLE_format_consensuses_new_1.txt \n",
    "--overwrite --estimateErrors --calculateLKfinalTree \n",
    "--output /nfs/research/goldman/zihao/errorsProject_1/MAPLE/new_version_MAY/MAPLE0.3.2_rateVar_errors_realData_checkingErrors_new_all \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
